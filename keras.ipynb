{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputation using Keras\n",
    "\n",
    "- This notebook provides a simple method to imputing missing values, and provides code for making a submission file.\n",
    "- EDA revealed F_2 columns are missing no values\n",
    "- all columns uncorrelated except for F_4*\n",
    "- this means the best estimator for missing values for F_1,F_3 is the mean (since competition metric is RMSE)\n",
    "- we only need to impute F_4*\n",
    "\n",
    "Here we fit a Keras model for each column of F_4*. \n",
    "- for each column we create a training set of only the records that are not missing values\n",
    "- we use dropout to help learn to deal with missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\orovi\\anaconda3\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.3.0 and strictly below 2.6.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.6.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import gc\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import layers as L\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau,EarlyStopping,ModelCheckpoint\n",
    "from tensorflow_addons.activations import mish\n",
    "from tensorflow_addons.layers import WeightNormalization\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', '{:.3f}'.format)\n",
    "\n",
    "RANDOM_STATE=42\n",
    "INPUT_PATH = Path('./input')\n",
    "P=1/55"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/ryancheunggit/tabular_dae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 30 12:41:22 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 512.95       Driver Version: 512.95       CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:06:00.0  On |                  N/A |\n",
      "| 32%   59C    P2    40W / 120W |   5803MiB /  6144MiB |     33%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2072    C+G   ...ge\\Application\\msedge.exe    N/A      |\n",
      "|    0   N/A  N/A      2140      C   ...a3\\envs\\kaggle\\python.exe    N/A      |\n",
      "|    0   N/A  N/A      5232    C+G   ...me\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A      9384    C+G   ...8wekyb3d8bbwe\\GameBar.exe    N/A      |\n",
      "|    0   N/A  N/A      9900    C+G   ...wekyb3d8bbwe\\Video.UI.exe    N/A      |\n",
      "|    0   N/A  N/A     10424    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A     11740    C+G   ...bbwe\\Microsoft.Photos.exe    N/A      |\n",
      "|    0   N/A  N/A     11904    C+G   ...n1h2txyewy\\SearchHost.exe    N/A      |\n",
      "|    0   N/A  N/A     11928    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     12024    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     12244      C   ...a3\\envs\\kaggle\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     12916    C+G   ...ekyb3d8bbwe\\YourPhone.exe    N/A      |\n",
      "|    0   N/A  N/A     13296    C+G   ...lack\\app-4.26.2\\slack.exe    N/A      |\n",
      "|    0   N/A  N/A     13664    C+G   ...txyewy\\MiniSearchHost.exe    N/A      |\n",
      "|    0   N/A  N/A     13780    C+G   ...cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "|    0   N/A  N/A     15512    C+G   ...264.37\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A     16216    C+G   ...8wekyb3d8bbwe\\Cortana.exe    N/A      |\n",
      "|    0   N/A  N/A     16696    C+G   ...9.0.3.0\\GoogleDriveFS.exe    N/A      |\n",
      "|    0   N/A  N/A     18364    C+G   ...ropbox\\Client\\Dropbox.exe    N/A      |\n",
      "|    0   N/A  N/A     27288      C   ...rovi\\anaconda3\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     28208    C+G   ...264.37\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A     32188      C   ...rovi\\anaconda3\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     33212    C+G   ...perience\\NVIDIA Share.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {'row_id' : 'int',\n",
    "          'F_2_0' : 'int', 'F_2_1' : 'int', 'F_2_2' : 'int',\n",
    "          'F_2_3' : 'int', 'F_2_4' : 'int', 'F_2_5' : 'int', \n",
    "          'F_2_6' : 'int', 'F_2_7' : 'int', 'F_2_8' : 'int',\n",
    "          'F_2_9' : 'int', 'F_2_10' : 'int', 'F_2_11' : 'int',\n",
    "          'F_2_12' : 'int', 'F_2_13' : 'int', 'F_2_14' : 'int',\n",
    "          'F_2_15' : 'int', 'F_2_16' : 'int', 'F_2_17' : 'int',\n",
    "          'F_2_18' : 'int', 'F_2_19' : 'int', 'F_2_20' : 'int',\n",
    "          'F_2_21' : 'int', 'F_2_22' : 'int', 'F_2_23' : 'int',\n",
    "          'F_2_24' : 'int'}\n",
    "\n",
    "data = pd.read_csv(INPUT_PATH / 'data.csv', \n",
    "                   index_col='row_id',\n",
    "                   dtype = dtypes)\n",
    "submission = pd.read_csv(INPUT_PATH / 'sample_submission.csv', \n",
    "                         index_col='row-col')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F_1_0</th>\n",
       "      <th>F_1_1</th>\n",
       "      <th>F_1_2</th>\n",
       "      <th>F_1_3</th>\n",
       "      <th>F_1_4</th>\n",
       "      <th>F_1_5</th>\n",
       "      <th>F_1_6</th>\n",
       "      <th>F_1_7</th>\n",
       "      <th>F_1_8</th>\n",
       "      <th>F_1_9</th>\n",
       "      <th>F_1_10</th>\n",
       "      <th>F_1_11</th>\n",
       "      <th>F_1_12</th>\n",
       "      <th>F_1_13</th>\n",
       "      <th>F_1_14</th>\n",
       "      <th>F_2_0</th>\n",
       "      <th>F_2_1</th>\n",
       "      <th>F_2_2</th>\n",
       "      <th>F_2_3</th>\n",
       "      <th>F_2_4</th>\n",
       "      <th>F_2_5</th>\n",
       "      <th>F_2_6</th>\n",
       "      <th>F_2_7</th>\n",
       "      <th>F_2_8</th>\n",
       "      <th>F_2_9</th>\n",
       "      <th>F_2_10</th>\n",
       "      <th>F_2_11</th>\n",
       "      <th>F_2_12</th>\n",
       "      <th>F_2_13</th>\n",
       "      <th>F_2_14</th>\n",
       "      <th>F_2_15</th>\n",
       "      <th>F_2_16</th>\n",
       "      <th>F_2_17</th>\n",
       "      <th>F_2_18</th>\n",
       "      <th>F_2_19</th>\n",
       "      <th>F_2_20</th>\n",
       "      <th>F_2_21</th>\n",
       "      <th>F_2_22</th>\n",
       "      <th>F_2_23</th>\n",
       "      <th>F_2_24</th>\n",
       "      <th>F_3_0</th>\n",
       "      <th>F_3_1</th>\n",
       "      <th>F_3_2</th>\n",
       "      <th>F_3_3</th>\n",
       "      <th>F_3_4</th>\n",
       "      <th>F_3_5</th>\n",
       "      <th>F_3_6</th>\n",
       "      <th>F_3_7</th>\n",
       "      <th>F_3_8</th>\n",
       "      <th>F_3_9</th>\n",
       "      <th>F_3_10</th>\n",
       "      <th>F_3_11</th>\n",
       "      <th>F_3_12</th>\n",
       "      <th>F_3_13</th>\n",
       "      <th>F_3_14</th>\n",
       "      <th>F_3_15</th>\n",
       "      <th>F_3_16</th>\n",
       "      <th>F_3_17</th>\n",
       "      <th>F_3_18</th>\n",
       "      <th>F_3_19</th>\n",
       "      <th>F_3_20</th>\n",
       "      <th>F_3_21</th>\n",
       "      <th>F_3_22</th>\n",
       "      <th>F_3_23</th>\n",
       "      <th>F_3_24</th>\n",
       "      <th>F_4_0</th>\n",
       "      <th>F_4_1</th>\n",
       "      <th>F_4_2</th>\n",
       "      <th>F_4_3</th>\n",
       "      <th>F_4_4</th>\n",
       "      <th>F_4_5</th>\n",
       "      <th>F_4_6</th>\n",
       "      <th>F_4_7</th>\n",
       "      <th>F_4_8</th>\n",
       "      <th>F_4_9</th>\n",
       "      <th>F_4_10</th>\n",
       "      <th>F_4_11</th>\n",
       "      <th>F_4_12</th>\n",
       "      <th>F_4_13</th>\n",
       "      <th>F_4_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-4.664</td>\n",
       "      <td>-4.791</td>\n",
       "      <td>-4.871</td>\n",
       "      <td>-5.053</td>\n",
       "      <td>-5.363</td>\n",
       "      <td>-5.508</td>\n",
       "      <td>-5.199</td>\n",
       "      <td>-6.990</td>\n",
       "      <td>-4.567</td>\n",
       "      <td>-4.998</td>\n",
       "      <td>-4.795</td>\n",
       "      <td>-4.612</td>\n",
       "      <td>-7.063</td>\n",
       "      <td>-6.896</td>\n",
       "      <td>-4.630</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-4.694</td>\n",
       "      <td>-4.466</td>\n",
       "      <td>-4.886</td>\n",
       "      <td>-4.677</td>\n",
       "      <td>-5.009</td>\n",
       "      <td>-4.871</td>\n",
       "      <td>-5.019</td>\n",
       "      <td>-5.053</td>\n",
       "      <td>-5.508</td>\n",
       "      <td>-4.846</td>\n",
       "      <td>-4.626</td>\n",
       "      <td>-4.598</td>\n",
       "      <td>-4.533</td>\n",
       "      <td>-4.747</td>\n",
       "      <td>-5.363</td>\n",
       "      <td>-4.448</td>\n",
       "      <td>-4.822</td>\n",
       "      <td>-4.806</td>\n",
       "      <td>-5.199</td>\n",
       "      <td>-6.069</td>\n",
       "      <td>-4.998</td>\n",
       "      <td>-7.147</td>\n",
       "      <td>-4.741</td>\n",
       "      <td>-5.251</td>\n",
       "      <td>-4.891</td>\n",
       "      <td>-12.878</td>\n",
       "      <td>-12.532</td>\n",
       "      <td>-9.663</td>\n",
       "      <td>-9.942</td>\n",
       "      <td>-12.825</td>\n",
       "      <td>-12.537</td>\n",
       "      <td>-11.132</td>\n",
       "      <td>-11.678</td>\n",
       "      <td>-10.092</td>\n",
       "      <td>-9.864</td>\n",
       "      <td>-10.354</td>\n",
       "      <td>-26.277</td>\n",
       "      <td>-11.524</td>\n",
       "      <td>-10.662</td>\n",
       "      <td>-9.984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>2.688</td>\n",
       "      <td>2.514</td>\n",
       "      <td>0.977</td>\n",
       "      <td>2.517</td>\n",
       "      <td>2.941</td>\n",
       "      <td>1.533</td>\n",
       "      <td>1.492</td>\n",
       "      <td>2.646</td>\n",
       "      <td>1.178</td>\n",
       "      <td>1.111</td>\n",
       "      <td>3.280</td>\n",
       "      <td>2.466</td>\n",
       "      <td>2.759</td>\n",
       "      <td>2.480</td>\n",
       "      <td>1.718</td>\n",
       "      <td>1.780</td>\n",
       "      <td>1.801</td>\n",
       "      <td>1.243</td>\n",
       "      <td>1.557</td>\n",
       "      <td>1.603</td>\n",
       "      <td>2.231</td>\n",
       "      <td>2.032</td>\n",
       "      <td>1.606</td>\n",
       "      <td>0.709</td>\n",
       "      <td>3.134</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.065</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.327</td>\n",
       "      <td>-0.331</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>-0.195</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.334</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.039</td>\n",
       "      <td>5.043</td>\n",
       "      <td>5.130</td>\n",
       "      <td>5.462</td>\n",
       "      <td>4.857</td>\n",
       "      <td>4.961</td>\n",
       "      <td>4.958</td>\n",
       "      <td>2.528</td>\n",
       "      <td>4.886</td>\n",
       "      <td>4.789</td>\n",
       "      <td>4.914</td>\n",
       "      <td>4.818</td>\n",
       "      <td>2.301</td>\n",
       "      <td>2.543</td>\n",
       "      <td>4.816</td>\n",
       "      <td>15.000</td>\n",
       "      <td>14.000</td>\n",
       "      <td>11.000</td>\n",
       "      <td>14.000</td>\n",
       "      <td>16.000</td>\n",
       "      <td>12.000</td>\n",
       "      <td>12.000</td>\n",
       "      <td>16.000</td>\n",
       "      <td>13.000</td>\n",
       "      <td>11.000</td>\n",
       "      <td>17.000</td>\n",
       "      <td>13.000</td>\n",
       "      <td>15.000</td>\n",
       "      <td>15.000</td>\n",
       "      <td>13.000</td>\n",
       "      <td>13.000</td>\n",
       "      <td>13.000</td>\n",
       "      <td>12.000</td>\n",
       "      <td>15.000</td>\n",
       "      <td>13.000</td>\n",
       "      <td>14.000</td>\n",
       "      <td>15.000</td>\n",
       "      <td>16.000</td>\n",
       "      <td>11.000</td>\n",
       "      <td>17.000</td>\n",
       "      <td>4.587</td>\n",
       "      <td>4.851</td>\n",
       "      <td>4.763</td>\n",
       "      <td>4.988</td>\n",
       "      <td>4.722</td>\n",
       "      <td>5.039</td>\n",
       "      <td>4.525</td>\n",
       "      <td>5.462</td>\n",
       "      <td>5.107</td>\n",
       "      <td>5.101</td>\n",
       "      <td>5.130</td>\n",
       "      <td>4.685</td>\n",
       "      <td>4.943</td>\n",
       "      <td>4.710</td>\n",
       "      <td>4.820</td>\n",
       "      <td>5.248</td>\n",
       "      <td>4.839</td>\n",
       "      <td>5.058</td>\n",
       "      <td>4.961</td>\n",
       "      <td>2.666</td>\n",
       "      <td>6.032</td>\n",
       "      <td>2.392</td>\n",
       "      <td>4.967</td>\n",
       "      <td>4.809</td>\n",
       "      <td>4.981</td>\n",
       "      <td>10.657</td>\n",
       "      <td>11.674</td>\n",
       "      <td>2.909</td>\n",
       "      <td>2.582</td>\n",
       "      <td>11.927</td>\n",
       "      <td>13.540</td>\n",
       "      <td>11.525</td>\n",
       "      <td>12.536</td>\n",
       "      <td>2.607</td>\n",
       "      <td>2.815</td>\n",
       "      <td>2.548</td>\n",
       "      <td>31.229</td>\n",
       "      <td>11.342</td>\n",
       "      <td>11.901</td>\n",
       "      <td>2.584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      F_1_0  F_1_1  F_1_2  F_1_3  F_1_4  F_1_5  F_1_6  F_1_7  F_1_8  F_1_9  \\\n",
       "min  -4.664 -4.791 -4.871 -5.053 -5.363 -5.508 -5.199 -6.990 -4.567 -4.998   \n",
       "mean -0.001  0.002  0.001  0.001  0.002  0.001 -0.000 -0.064 -0.000  0.000   \n",
       "max   5.039  5.043  5.130  5.462  4.857  4.961  4.958  2.528  4.886  4.789   \n",
       "\n",
       "      F_1_10  F_1_11  F_1_12  F_1_13  F_1_14  F_2_0  F_2_1  F_2_2  F_2_3  \\\n",
       "min   -4.795  -4.612  -7.063  -6.896  -4.630  0.000  0.000  0.000  0.000   \n",
       "mean   0.000  -0.001  -0.061  -0.067  -0.001  2.688  2.514  0.977  2.517   \n",
       "max    4.914   4.818   2.301   2.543   4.816 15.000 14.000 11.000 14.000   \n",
       "\n",
       "      F_2_4  F_2_5  F_2_6  F_2_7  F_2_8  F_2_9  F_2_10  F_2_11  F_2_12  \\\n",
       "min   0.000  0.000  0.000  0.000  0.000  0.000   0.000   0.000   0.000   \n",
       "mean  2.941  1.533  1.492  2.646  1.178  1.111   3.280   2.466   2.759   \n",
       "max  16.000 12.000 12.000 16.000 13.000 11.000  17.000  13.000  15.000   \n",
       "\n",
       "      F_2_13  F_2_14  F_2_15  F_2_16  F_2_17  F_2_18  F_2_19  F_2_20  F_2_21  \\\n",
       "min    0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000   \n",
       "mean   2.480   1.718   1.780   1.801   1.243   1.557   1.603   2.231   2.032   \n",
       "max   15.000  13.000  13.000  13.000  12.000  15.000  13.000  14.000  15.000   \n",
       "\n",
       "      F_2_22  F_2_23  F_2_24  F_3_0  F_3_1  F_3_2  F_3_3  F_3_4  F_3_5  F_3_6  \\\n",
       "min    0.000   0.000   0.000 -4.694 -4.466 -4.886 -4.677 -5.009 -4.871 -5.019   \n",
       "mean   1.606   0.709   3.134  0.002 -0.001  0.001  0.001  0.001 -0.002  0.000   \n",
       "max   16.000  11.000  17.000  4.587  4.851  4.763  4.988  4.722  5.039  4.525   \n",
       "\n",
       "      F_3_7  F_3_8  F_3_9  F_3_10  F_3_11  F_3_12  F_3_13  F_3_14  F_3_15  \\\n",
       "min  -5.053 -5.508 -4.846  -4.626  -4.598  -4.533  -4.747  -5.363  -4.448   \n",
       "mean  0.002  0.001 -0.000   0.002   0.001   0.000  -0.002   0.001  -0.002   \n",
       "max   5.462  5.107  5.101   5.130   4.685   4.943   4.710   4.820   5.248   \n",
       "\n",
       "      F_3_16  F_3_17  F_3_18  F_3_19  F_3_20  F_3_21  F_3_22  F_3_23  F_3_24  \\\n",
       "min   -4.822  -4.806  -5.199  -6.069  -4.998  -7.147  -4.741  -5.251  -4.891   \n",
       "mean  -0.001  -0.000   0.000  -0.065   0.002  -0.059   0.000   0.000  -0.001   \n",
       "max    4.839   5.058   4.961   2.666   6.032   2.392   4.967   4.809   4.981   \n",
       "\n",
       "       F_4_0   F_4_1  F_4_2  F_4_3   F_4_4   F_4_5   F_4_6   F_4_7   F_4_8  \\\n",
       "min  -12.878 -12.532 -9.663 -9.942 -12.825 -12.537 -11.132 -11.678 -10.092   \n",
       "mean   0.327  -0.331 -0.086 -0.195   0.333   0.336   0.004   0.334  -0.072   \n",
       "max   10.657  11.674  2.909  2.582  11.927  13.540  11.525  12.536   2.607   \n",
       "\n",
       "      F_4_9  F_4_10  F_4_11  F_4_12  F_4_13  F_4_14  \n",
       "min  -9.864 -10.354 -26.277 -11.524 -10.662  -9.984  \n",
       "mean -0.080   0.038   0.552   0.334   0.330   0.037  \n",
       "max   2.815   2.548  31.229  11.342  11.901   2.584  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can see that the values are acceptably small and don't have to be normalised\n",
    "data.agg(['min','mean','max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cols_by_prefix(columns, prefix):\n",
    "    return [x for x in columns if x.startswith(prefix)]\n",
    "\n",
    "cols_f1 = cols_by_prefix(data.columns, 'F_1')\n",
    "cols_f2 = cols_by_prefix(data.columns, 'F_2')\n",
    "cols_f3 = cols_by_prefix(data.columns, 'F_3')\n",
    "cols_f4 = cols_by_prefix(data.columns, 'F_4')\n",
    "cols_f134 = cols_f1 + cols_f3 + cols_f4\n",
    "cols_f123 = cols_f1 + cols_f2 + cols_f3\n",
    "\n",
    "data_f134 = data[cols_f134]\n",
    "data_f1 = data[cols_f1]\n",
    "data_f2 = data[cols_f2]\n",
    "data_f3 = data[cols_f3]\n",
    "data_f4 = data[cols_f4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_training(df, n, p, random_state):\n",
    "    # first find all rows with *no* NaN; sample n rows\n",
    "    df = df[~df.isnull().any(axis=1)]\n",
    "    if n > 0:\n",
    "        df = df.sample(n=n, random_state=random_state)\n",
    "    \n",
    "    # random mask of NaN locations; only cols F_1*, F_3*, F_4*\n",
    "    mask = np.random.random(df[cols_f134].shape) < p\n",
    "    df_na = df[cols_f134].mask(mask)\n",
    "\n",
    "    # put it back together with F_2*\n",
    "    df_na = pd.concat([df_na[cols_f1], df[cols_f2], df_na[cols_f3], df_na[cols_f4]], axis=1)\n",
    "    return df, df_na, df_na.isna().sum().sum()\n",
    "\n",
    "def sse_cols(df1, df2):\n",
    "    return ((df1 - df2).pow(2)).sum()\n",
    "\n",
    "def rmse(df1, df2, n):\n",
    "    return (sse_cols(df1, df2).sum()/n)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input_size=28, hidden_size=64):\n",
    "    \n",
    "    # Input:\n",
    "    inputF4 = L.Input(shape=input_size)\n",
    "\n",
    "    # Network:\n",
    "    x = L.Dense(units=hidden_size*4,  \n",
    "                kernel_regularizer=tf.keras.regularizers.l2(40e-6),\n",
    "                activation=mish)(inputF4)\n",
    "#    x = L.BatchNormalization()(x)\n",
    "    x = L.Dense(units=hidden_size*4, \n",
    "                kernel_regularizer=tf.keras.regularizers.l2(40e-6),\n",
    "                activation=mish)(x)\n",
    "#    x = L.BatchNormalization()(x)\n",
    "    x = L.Dense(units=hidden_size*2,\n",
    "                kernel_regularizer=tf.keras.regularizers.l2(40e-6),\n",
    "                activation=mish)(x)\n",
    "#    x = L.BatchNormalization()(x)\n",
    "    x = L.Dense(units=hidden_size, \n",
    "                kernel_regularizer=tf.keras.regularizers.l2(40e-6),\n",
    "                activation=mish)(x)\n",
    "#    x = L.BatchNormalization()(x)\n",
    "    x = L.Dense(units=1, activation='linear')(x)\n",
    "    \n",
    "    # Output:\n",
    "    model = tf.keras.Model(inputF4, x)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "        loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    "    )\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute mean for F1,F3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab a training subset\n",
    "train, train_na, na_count = make_training(data, -1, P, RANDOM_STATE)\n",
    "\n",
    "mean_imputer = SimpleImputer(strategy=\"mean\")\n",
    "\n",
    "# include F2 and passthrough just to retain column order\n",
    "mean_imputer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"mean1\", mean_imputer, cols_f1),\n",
    "        (\"mean2\", mean_imputer, cols_f2),\n",
    "        (\"mean3\", mean_imputer, cols_f3),\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "train_na[:] = mean_imputer.fit_transform(train_na)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteratively impute F4_* using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F_4_0\n",
      "train: (785497, 28), valid: (196375, 28), test: (18128, 28)\n",
      "train: (785497,), valid: (196375,)\n",
      "24547/24547 - 210s - loss: 405.4362 - root_mean_squared_error: 20.1219 - val_loss: 5.8766 - val_root_mean_squared_error: 2.2926\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cnt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m     21\u001b[0m     x\u001b[38;5;241m=\u001b[39mx_train, y\u001b[38;5;241m=\u001b[39my_train, \n\u001b[0;32m     22\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39m(x_valid, y_valid),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m     ]\n\u001b[0;32m     31\u001b[0m )\n\u001b[0;32m     32\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(x_valid)\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFFNN: cnt=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcnt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, col=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, RMSE=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmean_squared_error(y_valid,y_pred,squared\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cnt' is not defined"
     ]
    }
   ],
   "source": [
    "for col in ['F_4_0']:\n",
    "    print(col)\n",
    "    x_train = data_f4[data_f4[col].notna()]\n",
    "    x_test = data_f4[data_f4[col].isna()]\n",
    "\n",
    "    x_train, x_valid = train_test_split(x_train, test_size=0.20)\n",
    "    y_train = x_train.pop(col)\n",
    "    y_valid = x_valid.pop(col)\n",
    "    x_test.pop(col)\n",
    "\n",
    "    imputer = SimpleImputer(strategy=\"constant\", fill_value=-128, add_indicator=True)\n",
    "    x_train = imputer.fit_transform(x_train)\n",
    "    x_valid = imputer.fit_transform(x_valid)\n",
    "    x_test = imputer.fit_transform(x_test)\n",
    "    \n",
    "    print(f'train: {x_train.shape}, valid: {x_valid.shape}, test: {x_test.shape}')\n",
    "    print(f'train: {y_train.shape}, valid: {y_valid.shape}')\n",
    "\n",
    "    model = get_model()\n",
    "    history = model.fit(\n",
    "        x=x_train, y=y_train, \n",
    "        validation_data=(x_valid, y_valid),\n",
    "        epochs=2, \n",
    "        verbose=2,\n",
    "        callbacks=[\n",
    "            ReduceLROnPlateau(monitor='val_loss',mode='min',\n",
    "                verbose=0,factor=0.5,patience=3),\n",
    "            EarlyStopping(mode='min',restore_best_weights=True,\n",
    "                verbose=0,min_delta=1e-4,patience=10),\n",
    "        ]\n",
    "    )\n",
    "    y_pred = model.predict(x_valid)\n",
    "    print(f'FFNN: col={col}, RMSE={mean_squared_error(y_valid,y_pred,squared=False)}')        \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "callbacks=[ReduceLROnPlateau(monitor='val_loss',mode='min',\n",
    "                             verbose=0,factor=0.5,patience=3),\n",
    "           EarlyStopping(mode='min',restore_best_weights=True,\n",
    "                         verbose=0,min_delta=1e-4,patience=10)\n",
    "          ]\n",
    "\n",
    "estimator = KerasClassifier(build_fn=lambda: get_model(),\n",
    "                            epochs=1, \n",
    "                            validation_split=0.2,\n",
    "                            callbacks=callbacks)\n",
    "                            \n",
    "iter_imputer = IterativeImputer(estimator=estimator,\n",
    "                                max_iter=1,\n",
    "                                verbose=2,\n",
    "                                random_state=RANDOM_STATE)\n",
    "\n",
    "train_na[cols_f4] = iter_imputer.fit_transform(train_na[cols_f4].to_numpy())\n",
    "print(f'RMSE={rmse(train, train_na, na_count)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_na['F_4_0']\n",
    "X_train = train_na[cols_f4].drop(columns='F_4_0')\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X_train.iloc[0].to_numpy().shape)\n",
    "estimator.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, col):\n",
    "    X_train = df[df[col].notna()]\n",
    "    y_train = X_train[col]\n",
    "    X_train = X_train.drop(columns=col)\n",
    "    \n",
    "    X_test = df[df[col].isna()]\n",
    "    X_test = X_test.drop(columns=col)\n",
    "    return X_train, y_train, X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fit_model(df, col):\n",
    "\n",
    "    print(f'**** imputing {col}')\n",
    "    X_train, y_train, X_test = train_test_split(df[cols_f4], col)\n",
    "    print(f'{X_train.shape}, {y_train.shape}, {X_test.shape}')\n",
    "\n",
    "    X_train = X_train.fillna(-1000)\n",
    "    X_test = X_test.fillna(-1000)\n",
    "\n",
    "    model = get_model(X_train.shape[1])\n",
    "    model.fit(X_train, y_train, validation_split=0.1,\n",
    "              epochs=300, \n",
    "            callbacks=[\n",
    "                ReduceLROnPlateau(monitor='val_loss',mode='min',\n",
    "                    verbose=0,factor=0.5,patience=3),\n",
    "                EarlyStopping(mode='min',restore_best_weights=True,\n",
    "                    verbose=0,min_delta=1e-4,patience=10),\n",
    "                ModelCheckpoint(f'model_{col}.hdf5',monitor='val_loss',mode='min',\n",
    "                    verbose=0,save_best_only=True,save_weights_only=True),\n",
    "            ]      \n",
    "             )\n",
    "    model.load_weights(f'model_{cnt}_{col}.hdf5')\n",
    "    return model.predict(X_test)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = {}\n",
    "\n",
    "for col in cols_f4:\n",
    "    preds = fit_model(train_na, col)\n",
    "    all_preds[col] = preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def update_preds(df, all_preds):\n",
    "    for col in all_preds.keys():\n",
    "        print(col)\n",
    "        preds = all_preds[col]\n",
    "        df.update(preds)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_na = update_preds(train_na, all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse(train, train_na, na_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[:] = imputer.fit_transform(data)\n",
    "all_preds = fit_model(data)\n",
    "data = update_preds(data, all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_submission(data):\n",
    "    new_submission = submission.copy(deep=True)\n",
    "    for i in tqdm(new_submission.index):\n",
    "        row = int(i.split('-')[0])\n",
    "        col = i.split('-')[1]\n",
    "        new_submission.loc[i, 'value'] = data.loc[row, col]\n",
    "\n",
    "    new_submission.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_submission(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0 10100 00000 XaVu9\n",
      "2 0 10100 00000 XaVu9\n",
      "1 1 10100 00000 XaVu9\n",
      "2 1 00000 00000 XaVu9\n",
      "1 0 00000 00000 XaVu9\n",
      "2 0 00000 00000 XaVu9\n",
      "1 0 00000 00000 XaVu9\n",
      "2 0 00000 00000 XaVu9\n",
      "1 0 00000 00000 XaVu9\n",
      "2 0 00000 00000 XaVu9\n",
      "1 0 00000 00000 XaVu9\n",
      "2 0 00000 00000 XaVu9\n",
      "1 0 00000 00000 XaVu9\n",
      "2 0 00000 00000 XaVu9\n",
      "1 0 00000 00000 XaVu9\n",
      "2 0 00000 00000 XaVu9\n",
      "1 0 00000 00000 XaVu9\n",
      "2 0 00000 00000 XaVu9\n",
      "1 a 00000 00000 1aVu9\n",
      "2 a 00000 00000 10Vu9\n",
      "1 u 00000 00000 101u9\n",
      "2 u 00000 00000 10109\n",
      "1 9 00000 00000 10109\n",
      "2 9 00000 00000 10100\n",
      "00000 00000 10100\n"
     ]
    }
   ],
   "source": [
    "id = \"A0100 00000 XaVu9\"\n",
    "for i in id:\n",
    "    if i.isupper() == True:\n",
    "        id = id.replace(i,\"1\")\n",
    "    elif i == \" \":\n",
    "        id = id.replace(i,\" \")\n",
    "    else:\n",
    "        print(1,i,id)\n",
    "        id = id.replace(i,\"0\")\n",
    "        print(2,i,id)\n",
    "print (id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 00000 10100\n"
     ]
    }
   ],
   "source": [
    "old = \"A0100 00000 XaVu9\"\n",
    "new = []\n",
    "for i in old:\n",
    "    if i.isupper() == True:\n",
    "        new.append(\"1\")\n",
    "    elif i == \" \":\n",
    "        new.append(\" \")\n",
    "    else:\n",
    "        new.append(\"0\")\n",
    "print (''.join(new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
