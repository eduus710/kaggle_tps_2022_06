{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e88741f",
   "metadata": {
    "papermill": {
     "duration": 0.003211,
     "end_time": "2022-06-27T22:45:59.759655",
     "exception": false,
     "start_time": "2022-06-27T22:45:59.756444",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Thank you @ehekatlact for sharing the idea of using the na count of each record, and @hiro5299834 and @edrickkesuma for the great improvements, please upvote the following notebooks:\n",
    "* https://www.kaggle.com/code/ehekatlact/tps2206-the-na-count-of-each-record-is-critical\n",
    "* https://www.kaggle.com/code/hiro5299834/tps-jun-2022-pytorch-lightning-with-na-counts\n",
    "* https://www.kaggle.com/code/edrickkesuma/np-random-top-public-notebook\n",
    "\n",
    "Since the notebooks above were made using PyTorch, I thought it would be very interesting and fun to create a TensorFlow implementation of this idea. The only modifications I made besides the translation to TensorFlow were:\n",
    "* Using weight normalization in the dense layers.\n",
    "* Pre-calculating a matrix of negative ones whose rows are randomly shuffled through \"tf.keras.utils.Sequence\" at each epoch.\n",
    "\n",
    "I tried to make it as simple as possible. I hope you find it as interesting as I did. Thank you for reading!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd769271",
   "metadata": {
    "papermill": {
     "duration": 10.9333,
     "end_time": "2022-06-27T22:46:10.695772",
     "exception": false,
     "start_time": "2022-06-27T22:45:59.762472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\orovi\\anaconda3\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.3.0 and strictly below 2.6.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.6.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os, random\n",
    "from datetime import datetime\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Tensorflow:\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import layers as L\n",
    "from tensorflow_addons.activations import mish\n",
    "from tensorflow_addons.layers import WeightNormalization\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau,EarlyStopping,ModelCheckpoint\n",
    "\n",
    "RANDOM_STATE=1967"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b5ee92d",
   "metadata": {
    "papermill": {
     "duration": 18.795555,
     "end_time": "2022-06-27T22:46:29.493989",
     "exception": false,
     "start_time": "2022-06-27T22:46:10.698434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    759268\n",
       "1    211342\n",
       "2     27127\n",
       "3      2124\n",
       "4       135\n",
       "5         4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input:\n",
    "data = pd.read_csv('./input/data.csv',index_col=0)\n",
    "sample_submission = pd.read_csv('./input/sample_submission.csv',index_col=0)\n",
    "\n",
    "# Column groups:\n",
    "f1col = [x for x in data.columns if x.startswith('F_1')]\n",
    "f2col = [x for x in data.columns if x.startswith('F_2')]\n",
    "f3col = [x for x in data.columns if x.startswith('F_3')]\n",
    "f4col = [x for x in data.columns if x.startswith('F_4')]\n",
    "\n",
    "# Mean imputation for F1 and F3 columns:\n",
    "data[f1col+f3col] = data[f1col+f3col].fillna(data[f1col+f3col].mean())\n",
    "\n",
    "# Minus one imputation of F4 columns in the testing set:\n",
    "data_test = data.copy()\n",
    "data_test[f4col] = data_test[f4col].fillna(-1)\n",
    "\n",
    "# Row-wise NaN counts of F4 columns:\n",
    "data[f4col].isna().sum(axis=1).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "314a358b",
   "metadata": {
    "papermill": {
     "duration": 0.021606,
     "end_time": "2022-06-27T22:46:29.518381",
     "exception": false,
     "start_time": "2022-06-27T22:46:29.496775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_model(hidden_size=64):\n",
    "    \n",
    "    # Input:\n",
    "    inputF4 = L.Input(shape=len(f4col)-1)\n",
    "\n",
    "    # Network:\n",
    "    x = L.Dense(units=hidden_size*4,  \n",
    "                kernel_regularizer=tf.keras.regularizers.l2(40e-6),\n",
    "                activation=mish)(inputF4)\n",
    "#    x = L.BatchNormalization()(x)\n",
    "    x = L.Dense(units=hidden_size*4, \n",
    "                kernel_regularizer=tf.keras.regularizers.l2(40e-6),\n",
    "                activation=mish)(x)\n",
    "#    x = L.BatchNormalization()(x)\n",
    "    x = L.Dense(units=hidden_size*2,\n",
    "                kernel_regularizer=tf.keras.regularizers.l2(40e-6),\n",
    "                activation=mish)(x)\n",
    "#    x = L.BatchNormalization()(x)\n",
    "    x = L.Dense(units=hidden_size, \n",
    "                kernel_regularizer=tf.keras.regularizers.l2(40e-6),\n",
    "                activation=mish)(x)\n",
    "#    x = L.BatchNormalization()(x)\n",
    "    x = L.Dense(units=1, activation='linear')(x)\n",
    "    \n",
    "    # Output:\n",
    "    model = tf.keras.Model(inputF4, x)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "        loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    "    )\n",
    "    return(model)\n",
    "\n",
    "class CustomDataset(tf.keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, X, y, noise, batch_size=256, random_state=42):\n",
    "        '''initialize dataset and noise positions'''\n",
    "        np.random.seed(random_state)\n",
    "        tf.random.set_seed(random_state)\n",
    "        self.X, self.y, self.noise = X, y, noise\n",
    "        self.batch_size = batch_size\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __len__(self):\n",
    "        '''number of batches per epoch'''\n",
    "        return self.X.shape[0] // self.batch_size\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        '''generate batch and Randomly add -1 to the training and validation sets\n",
    "        in the same amount as expected in the testing set'''\n",
    "        batch_indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        batch_noises = self.noiseindexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        X_batch, y_batch = self.X[batch_indexes], self.y[batch_indexes]\n",
    "        for i in range(self.noise.shape[1]):\n",
    "            X_batch[range(self.batch_size),self.noise[batch_noises,i]] = -1  \n",
    "        return X_batch, y_batch\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        '''shuffle the training set as well as the -1 positions'''\n",
    "        self.indexes = np.arange(len(self.X))\n",
    "        self.noiseindexes = np.arange(len(self.noise))\n",
    "        np.random.shuffle(self.indexes)\n",
    "        np.random.shuffle(self.noiseindexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247fd146",
   "metadata": {
    "papermill": {
     "duration": 0.002918,
     "end_time": "2022-06-27T22:46:29.524733",
     "exception": false,
     "start_time": "2022-06-27T22:46:29.521815",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Change the line below to \"True\" to create the models instead of loading from the dataset. I created the models in my personal computer and uploaded them afterwards since I almost run out of GPU time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39dd9bcd",
   "metadata": {
    "papermill": {
     "duration": 0.011086,
     "end_time": "2022-06-27T22:46:29.539231",
     "exception": false,
     "start_time": "2022-06-27T22:46:29.528145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5874353b",
   "metadata": {
    "papermill": {
     "duration": 2443.626112,
     "end_time": "2022-06-27T23:27:13.168617",
     "exception": false,
     "start_time": "2022-06-27T22:46:29.542505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** 07:12:15 FITTING F_4_0-0\n",
      "x_test shape: (14175, 14)\n",
      "FFNN: cnt=1, col=F_4_0, RMSE=0.011026984679419075\n",
      "***** 07:24:33 FITTING F_4_1-0\n",
      "x_test shape: (14136, 14)\n",
      "FFNN: cnt=1, col=F_4_1, RMSE=0.00973634833254945\n",
      "***** 07:33:33 FITTING F_4_2-0\n",
      "x_test shape: (14248, 14)\n",
      "FFNN: cnt=1, col=F_4_2, RMSE=0.008351973182809185\n",
      "***** 07:40:43 FITTING F_4_3-0\n",
      "x_test shape: (13968, 14)\n",
      "FFNN: cnt=1, col=F_4_3, RMSE=0.03490054361915114\n",
      "***** 07:44:20 FITTING F_4_4-0\n",
      "x_test shape: (13963, 14)\n",
      "FFNN: cnt=1, col=F_4_4, RMSE=0.008366267836842755\n",
      "***** 07:51:30 FITTING F_4_5-0\n",
      "x_test shape: (14030, 14)\n",
      "FFNN: cnt=1, col=F_4_5, RMSE=0.008576107699857387\n",
      "***** 07:59:56 FITTING F_4_6-0\n",
      "x_test shape: (14201, 14)\n",
      "FFNN: cnt=1, col=F_4_6, RMSE=0.013529743386085409\n",
      "***** 08:12:43 FITTING F_4_7-0\n",
      "x_test shape: (13994, 14)\n",
      "FFNN: cnt=1, col=F_4_7, RMSE=0.007745134700627013\n",
      "***** 08:20:57 FITTING F_4_8-0\n",
      "x_test shape: (13971, 14)\n",
      "FFNN: cnt=1, col=F_4_8, RMSE=0.010057840820294825\n",
      "***** 08:26:05 FITTING F_4_9-0\n",
      "x_test shape: (14166, 14)\n",
      "FFNN: cnt=1, col=F_4_9, RMSE=0.013663179856943434\n",
      "***** 08:34:34 FITTING F_4_10-0\n",
      "x_test shape: (14198, 14)\n",
      "FFNN: cnt=1, col=F_4_10, RMSE=0.006864438640613855\n",
      "***** 08:40:37 FITTING F_4_11-0\n",
      "x_test shape: (14002, 14)\n",
      "FFNN: cnt=1, col=F_4_11, RMSE=0.009569159097053616\n",
      "***** 08:48:11 FITTING F_4_12-0\n",
      "x_test shape: (14162, 14)\n",
      "FFNN: cnt=1, col=F_4_12, RMSE=0.008746841500862124\n",
      "***** 08:57:14 FITTING F_4_13-0\n",
      "x_test shape: (13971, 14)\n",
      "FFNN: cnt=1, col=F_4_13, RMSE=0.0069509589497705505\n",
      "***** 09:04:01 FITTING F_4_14-0\n",
      "x_test shape: (14157, 14)\n",
      "FFNN: cnt=1, col=F_4_14, RMSE=0.00968378844790663\n",
      "***** 09:10:18 FITTING F_4_0-1\n",
      "x_test shape: (3477, 14)\n",
      "FFNN: cnt=2, col=F_4_0, RMSE=0.9754137882289216\n",
      "***** 09:22:44 FITTING F_4_1-1\n",
      "x_test shape: (3573, 14)\n",
      "FFNN: cnt=2, col=F_4_1, RMSE=0.8694080070965323\n",
      "***** 09:38:20 FITTING F_4_2-1\n",
      "x_test shape: (3771, 14)\n",
      "FFNN: cnt=2, col=F_4_2, RMSE=0.36008694121864265\n",
      "***** 09:53:19 FITTING F_4_3-1\n",
      "x_test shape: (3606, 14)\n",
      "FFNN: cnt=2, col=F_4_3, RMSE=0.3850763630593872\n",
      "***** 10:05:38 FITTING F_4_4-1\n",
      "x_test shape: (3525, 14)\n",
      "FFNN: cnt=2, col=F_4_4, RMSE=0.6820019301415715\n",
      "***** 10:21:45 FITTING F_4_5-1\n",
      "x_test shape: (3587, 14)\n",
      "FFNN: cnt=2, col=F_4_5, RMSE=0.7403996184614262\n",
      "***** 10:39:09 FITTING F_4_6-1\n",
      "x_test shape: (3645, 14)\n",
      "FFNN: cnt=2, col=F_4_6, RMSE=0.9497727863128678\n",
      "***** 10:58:53 FITTING F_4_7-1\n",
      "x_test shape: (3589, 14)\n",
      "FFNN: cnt=2, col=F_4_7, RMSE=0.9053700486397179\n",
      "***** 11:15:44 FITTING F_4_8-1\n",
      "x_test shape: (3719, 14)\n",
      "FFNN: cnt=2, col=F_4_8, RMSE=0.24059439772583807\n",
      "***** 11:27:40 FITTING F_4_9-1\n",
      "x_test shape: (3619, 14)\n",
      "FFNN: cnt=2, col=F_4_9, RMSE=0.3607634202776559\n",
      "***** 11:40:13 FITTING F_4_10-1\n",
      "x_test shape: (3594, 14)\n",
      "FFNN: cnt=2, col=F_4_10, RMSE=0.32192360809422305\n",
      "***** 11:53:30 FITTING F_4_11-1\n",
      "x_test shape: (3644, 14)\n",
      "FFNN: cnt=2, col=F_4_11, RMSE=0.6145925921578436\n",
      "***** 12:10:22 FITTING F_4_12-1\n",
      "x_test shape: (3672, 14)\n",
      "FFNN: cnt=2, col=F_4_12, RMSE=0.8410424834865604\n",
      "***** 12:26:52 FITTING F_4_13-1\n",
      "x_test shape: (3600, 14)\n",
      "FFNN: cnt=2, col=F_4_13, RMSE=0.6292421999014706\n",
      "***** 12:47:59 FITTING F_4_14-1\n",
      "x_test shape: (3633, 14)\n",
      "FFNN: cnt=2, col=F_4_14, RMSE=0.26672271060098557\n",
      "***** 12:57:52 FITTING F_4_0-2\n",
      "x_test shape: (431, 14)\n",
      "FFNN: cnt=3, col=F_4_0, RMSE=1.2598628159655636\n",
      "***** 13:11:59 FITTING F_4_1-2\n",
      "x_test shape: (422, 14)\n",
      "FFNN: cnt=3, col=F_4_1, RMSE=1.296179366036991\n",
      "***** 13:26:09 FITTING F_4_2-2\n",
      "x_test shape: (436, 14)\n",
      "FFNN: cnt=3, col=F_4_2, RMSE=0.4712598081154244\n",
      "***** 13:42:05 FITTING F_4_3-2\n",
      "x_test shape: (426, 14)\n",
      "FFNN: cnt=3, col=F_4_3, RMSE=0.4854733185786508\n",
      "***** 13:55:43 FITTING F_4_4-2\n",
      "x_test shape: (431, 14)\n",
      "FFNN: cnt=3, col=F_4_4, RMSE=1.0971650019870414\n",
      "***** 14:13:23 FITTING F_4_5-2\n",
      "x_test shape: (412, 14)\n",
      "FFNN: cnt=3, col=F_4_5, RMSE=1.1550430357157917\n",
      "***** 14:29:26 FITTING F_4_6-2\n",
      "x_test shape: (438, 14)\n",
      "FFNN: cnt=3, col=F_4_6, RMSE=1.3059426507741005\n",
      "***** 14:44:21 FITTING F_4_7-2\n",
      "x_test shape: (393, 14)\n",
      "FFNN: cnt=3, col=F_4_7, RMSE=1.2914527242558855\n",
      "***** 15:00:07 FITTING F_4_8-2\n",
      "x_test shape: (447, 14)\n",
      "FFNN: cnt=3, col=F_4_8, RMSE=0.3373858282686629\n",
      "***** 15:13:44 FITTING F_4_9-2\n",
      "x_test shape: (441, 14)\n",
      "FFNN: cnt=3, col=F_4_9, RMSE=0.4639459148511574\n",
      "***** 15:26:59 FITTING F_4_10-2\n",
      "x_test shape: (400, 14)\n",
      "FFNN: cnt=3, col=F_4_10, RMSE=0.4108484317695685\n",
      "***** 15:40:21 FITTING F_4_11-2\n",
      "x_test shape: (438, 14)\n",
      "FFNN: cnt=3, col=F_4_11, RMSE=1.140888584551815\n",
      "***** 15:54:08 FITTING F_4_12-2\n",
      "x_test shape: (431, 14)\n",
      "FFNN: cnt=3, col=F_4_12, RMSE=1.20771635456082\n",
      "***** 16:06:58 FITTING F_4_13-2\n",
      "x_test shape: (394, 14)\n",
      "FFNN: cnt=3, col=F_4_13, RMSE=1.0126583006954768\n",
      "***** 16:22:31 FITTING F_4_14-2\n",
      "x_test shape: (432, 14)\n",
      "FFNN: cnt=3, col=F_4_14, RMSE=0.37904257730428986\n",
      "***** 16:36:18 FITTING F_4_0-3\n",
      "x_test shape: (45, 14)\n",
      "FFNN: cnt=4, col=F_4_0, RMSE=1.4715706127955983\n",
      "***** 16:51:42 FITTING F_4_1-3\n",
      "x_test shape: (30, 14)\n",
      "FFNN: cnt=4, col=F_4_1, RMSE=1.4967415436912612\n",
      "***** 17:05:48 FITTING F_4_2-3\n",
      "x_test shape: (39, 14)\n",
      "FFNN: cnt=4, col=F_4_2, RMSE=0.5344310666934681\n",
      "***** 17:18:02 FITTING F_4_3-3\n",
      "x_test shape: (28, 14)\n",
      "FFNN: cnt=4, col=F_4_3, RMSE=0.548427318510501\n",
      "***** 17:31:01 FITTING F_4_4-3\n",
      "x_test shape: (37, 14)\n",
      "FFNN: cnt=4, col=F_4_4, RMSE=1.3582643123654516\n",
      "***** 17:44:04 FITTING F_4_5-3\n",
      "x_test shape: (33, 14)\n",
      "FFNN: cnt=4, col=F_4_5, RMSE=1.385968143444094\n",
      "***** 17:59:15 FITTING F_4_6-3\n",
      "x_test shape: (39, 14)\n",
      "FFNN: cnt=4, col=F_4_6, RMSE=1.5124276117659807\n",
      "***** 18:14:48 FITTING F_4_7-3\n",
      "x_test shape: (37, 14)\n",
      "FFNN: cnt=4, col=F_4_7, RMSE=1.5076410348096645\n",
      "***** 18:31:11 FITTING F_4_8-3\n",
      "x_test shape: (37, 14)\n",
      "FFNN: cnt=4, col=F_4_8, RMSE=0.4050661920266856\n",
      "***** 18:43:29 FITTING F_4_9-3\n",
      "x_test shape: (37, 14)\n",
      "FFNN: cnt=4, col=F_4_9, RMSE=0.5416844012041466\n",
      "***** 18:55:15 FITTING F_4_10-3\n",
      "x_test shape: (32, 14)\n",
      "FFNN: cnt=4, col=F_4_10, RMSE=0.4673827332444816\n",
      "***** 19:08:18 FITTING F_4_11-3\n",
      "x_test shape: (33, 14)\n",
      "FFNN: cnt=4, col=F_4_11, RMSE=1.557768268355242\n",
      "***** 19:22:44 FITTING F_4_12-3\n",
      "x_test shape: (39, 14)\n",
      "FFNN: cnt=4, col=F_4_12, RMSE=1.4472301110150136\n",
      "***** 19:38:01 FITTING F_4_13-3\n",
      "x_test shape: (30, 14)\n",
      "FFNN: cnt=4, col=F_4_13, RMSE=1.2488940670957775\n",
      "***** 19:51:52 FITTING F_4_14-3\n",
      "x_test shape: (44, 14)\n",
      "FFNN: cnt=4, col=F_4_14, RMSE=0.4577045489533608\n",
      "***** 20:02:08 FITTING F_4_0-4\n",
      "x_test shape: (0, 14)\n",
      "***** 20:02:08 FITTING F_4_1-4\n",
      "x_test shape: (3, 14)\n",
      "FFNN: cnt=5, col=F_4_1, RMSE=1.7036594509900183\n",
      "***** 20:16:57 FITTING F_4_2-4\n",
      "x_test shape: (1, 14)\n",
      "FFNN: cnt=5, col=F_4_2, RMSE=0.5940116171486782\n",
      "***** 20:27:33 FITTING F_4_3-4\n",
      "x_test shape: (1, 14)\n",
      "FFNN: cnt=5, col=F_4_3, RMSE=0.5970993351686227\n",
      "***** 20:39:09 FITTING F_4_4-4\n",
      "x_test shape: (1, 14)\n",
      "FFNN: cnt=5, col=F_4_4, RMSE=1.5806071927132017\n",
      "***** 20:50:56 FITTING F_4_5-4\n",
      "x_test shape: (1, 14)\n",
      "FFNN: cnt=5, col=F_4_5, RMSE=1.5804337736656944\n",
      "***** 21:04:26 FITTING F_4_6-4\n",
      "x_test shape: (2, 14)\n",
      "FFNN: cnt=5, col=F_4_6, RMSE=1.681102517657288\n",
      "***** 21:17:12 FITTING F_4_7-4\n",
      "x_test shape: (1, 14)\n",
      "FFNN: cnt=5, col=F_4_7, RMSE=1.6894758977018762\n",
      "***** 21:30:02 FITTING F_4_8-4\n",
      "x_test shape: (2, 14)\n",
      "FFNN: cnt=5, col=F_4_8, RMSE=0.46343703303629763\n",
      "***** 21:39:23 FITTING F_4_9-4\n",
      "x_test shape: (2, 14)\n",
      "FFNN: cnt=5, col=F_4_9, RMSE=0.5951141775226549\n",
      "***** 21:48:33 FITTING F_4_10-4\n",
      "x_test shape: (1, 14)\n",
      "FFNN: cnt=5, col=F_4_10, RMSE=0.51766036245255\n",
      "***** 22:00:33 FITTING F_4_11-4\n",
      "x_test shape: (2, 14)\n",
      "FFNN: cnt=5, col=F_4_11, RMSE=1.9847444587215664\n",
      "***** 22:15:47 FITTING F_4_12-4\n",
      "x_test shape: (2, 14)\n",
      "FFNN: cnt=5, col=F_4_12, RMSE=1.6277840431383601\n",
      "***** 22:24:15 FITTING F_4_13-4\n",
      "x_test shape: (0, 14)\n",
      "***** 22:24:15 FITTING F_4_14-4\n",
      "x_test shape: (1, 14)\n",
      "FFNN: cnt=5, col=F_4_14, RMSE=0.5102606524820014\n"
     ]
    }
   ],
   "source": [
    "result = data.copy()\n",
    "\n",
    "random.seed(RANDOM_STATE)\n",
    "np.random.seed(RANDOM_STATE)\n",
    "tf.random.set_seed(RANDOM_STATE)\n",
    "os.environ['PYTHONHASHSEED'] = str(RANDOM_STATE)\n",
    "    \n",
    "for cnt in range(5):\n",
    "    \n",
    "    # Prepare values which will be set to -1 during training:\n",
    "    noise = np.array([np.random.choice(\n",
    "        len(f4col)-1, size=cnt, replace=False\n",
    "    ) for _ in range(data.shape[0])])\n",
    "    \n",
    "    # Find rows with zero-nan and with \"cnt+1\" nans:\n",
    "    rownan0 = data[f4col].isna().sum(axis=1)==0\n",
    "    rownans = data[f4col].isna().sum(axis=1)==cnt+1\n",
    "    \n",
    "    for col in f4col:\n",
    "        \n",
    "        print(f'***** {datetime.now().strftime(\"%H:%M:%S\")} FITTING {col}-{cnt}')\n",
    "        # Get testing set from rows with the amount of nan given by the current 'cnt' value:\n",
    "        colna = data[col].isna()\n",
    "        X_test = data_test.loc[rownans&colna,f4col].drop(columns=col).values\n",
    "        print(\"x_test shape:\", X_test.shape)\n",
    "        \n",
    "        # If there are NaNs in the testing set:\n",
    "        if(X_test.shape[0]):\n",
    "        \n",
    "            # Get training and validation sets from zero-nan rows:\n",
    "            X = data.loc[rownan0,f4col]\n",
    "            y = X.pop(col)\n",
    "            X_train, X_valid, y_train, y_valid, noise_train, noise_valid = train_test_split(\n",
    "                X.values, y.values, noise[rownan0], train_size=0.8, random_state=cnt\n",
    "            )\n",
    "\n",
    "            # Training:\n",
    "            model = get_model()\n",
    "            if train:\n",
    "                history = model.fit(\n",
    "                    CustomDataset(X_train, y_train, noise_train), \n",
    "                    validation_data = CustomDataset(X_valid, y_valid, noise_valid),\n",
    "                    epochs=300, \n",
    "                    verbose=0,\n",
    "                    #use_multiprocessing=True, workers=4, \n",
    "                    callbacks=[\n",
    "                        ReduceLROnPlateau(monitor='val_loss',mode='min',\n",
    "                            verbose=0,factor=0.5,patience=3),\n",
    "                        EarlyStopping(mode='min',restore_best_weights=True,\n",
    "                            verbose=0,min_delta=1e-4,patience=10),\n",
    "                        ModelCheckpoint(f'model_{cnt}_{col}.hdf5',monitor='val_loss',mode='min',\n",
    "                            verbose=0,save_best_only=True,save_weights_only=True),\n",
    "                    ]\n",
    "                )\n",
    "                model.load_weights(f'model_{cnt}_{col}.hdf5')\n",
    "            else:\n",
    "                model.load_weights(f'model_{cnt}_{col}.hdf5')\n",
    "\n",
    "            # Performance:\n",
    "            for i in range(cnt):\n",
    "                X_valid[range(len(X_valid)),noise_valid[:,i]] = -1  \n",
    "            y_pred = model.predict(X_valid)\n",
    "            print(f'FFNN: cnt={cnt+1}, col={col}, RMSE={mean_squared_error(y_valid,y_pred,squared=False)}')        \n",
    "\n",
    "            # Inference:\n",
    "            result.loc[rownans&colna,col] = model.predict(X_test)\n",
    "            K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbbdc297",
   "metadata": {
    "papermill": {
     "duration": 82.625553,
     "end_time": "2022-06-27T23:28:35.801044",
     "exception": false,
     "start_time": "2022-06-27T23:27:13.175491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row-col</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0-F_1_14</th>\n",
       "      <td>-0.000905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-F_3_23</th>\n",
       "      <td>0.000365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-F_3_24</th>\n",
       "      <td>-0.000817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-F_1_2</th>\n",
       "      <td>0.000551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-F_4_2</th>\n",
       "      <td>0.377539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             value\n",
       "row-col           \n",
       "0-F_1_14 -0.000905\n",
       "0-F_3_23  0.000365\n",
       "1-F_3_24 -0.000817\n",
       "2-F_1_2   0.000551\n",
       "2-F_4_2   0.377539"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Submission:\n",
    "for i in sample_submission.index:\n",
    "    row, col = i.split('-')\n",
    "    sample_submission.loc[i,'value'] = result.loc[int(row),col]\n",
    "    \n",
    "sample_submission.to_csv('submission.csv')\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af434793",
   "metadata": {
    "papermill": {
     "duration": 0.006133,
     "end_time": "2022-06-27T23:28:35.813613",
     "exception": false,
     "start_time": "2022-06-27T23:28:35.807480",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Thank you for reading! Please let me know if you have any questions or suggestions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2567.858413,
   "end_time": "2022-06-27T23:28:38.740836",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-06-27T22:45:50.882423",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
